{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\" media=\"print\">\n",
    "    @media print {\n",
    "        @page { margin: 0; }\n",
    "        body { margin: 1.6cm; }\n",
    "        div.prompt.input_prompt { visibility:hidden; }\n",
    "        div.prompt.input_prompt:after { content:\"In [ ]\"; }\n",
    "        \n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Deep Learning - Median House Value Assesment Activity </center></h1>\n",
    "\n",
    "<b><center>April 9th, 2019</center></b>\n",
    " \n",
    "<b><center>Daniel Mínguez Camacho: dani.min.cam@gmail.com   </center></b>\n",
    "<b><center>Javier de la Rúa Martínez: javierdlrm@outlook.com </center></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](Images/Test.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Submitted to </b> <br>\n",
    "Martin Molina Gonzalez  <br>\n",
    "Daniel Manrique Gamo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"pagebreak\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction\n",
    "<br>\n",
    "<div style=\"text-align: justify\">This document is created as an assignment for Deep Learning course at Universidad Politécnica de Madrid. The aim of this report is describing the actions performed during the implementation of a deep network using tensorflow. </div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">The first section contains a description of the design process, how we installed the programming environment and the required libraries as well as how we built the network. Then we present the results and finally, we give a short conclusion of our experience during the work performed.  </div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">We won´t introduce formulas and other proofs of the different techniques because they are described in the class slides and can be easily found on the internet. We wanted also to reduce the extension of the document  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Problem\n",
    "<br>\n",
    "<div style=\"text-align: justify\">This California Housing Prices dataset has been downloaded from StatLib <a href=\"http://lib.stat.cmu.edu/datasets/\">repository</a>. It is based on data from the 1990 California census, what is not important for deep learning. The original dataset appeared in R. Kelley Pace and Ronald Barry, “Sparse Spatial Autoregressions,” Statistics & Probability Letters 33, no. 3 (1997): 291–297.</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">The problem proposed to solve in this assignment is to predict the house value based on the others variables present in the dataset.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data used\n",
    "<br>\n",
    "<div style=\"text-align: justify\">We have used the files MedianHouseValuePreparedCleanAttributes.csv and MedianHouseValueOneHotEncodedClasses.csv as described in the assignment description.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"><b>MedianHouseValuePreparedCleanAttributes.csv</b><br>The original dataset contained 20,640 instances corresponding to districts in california ranging from 600 to 3.000 people. This dataset has been previously cleaned, preprocessed and prepared with the following operations (described in class notes 2.1.1, slide 22):</div>\n",
    "<ul style=\"text-align: justify\">\n",
    "   <li>Total_bedrooms attribute has 207 missing values, (na or nan), which are removed since they are very little compared to the whole dataset.</li>\n",
    "   <li> Dataset is randomized.</li>\n",
    "   <li> Classes are encoded: first discretized and then one-hot encoded.</li>\n",
    "   <li> Attributes are individually re-scaled, normalized with a min-max scaling within the range [-1,1]: x-(max/2) / (max-min)/2.</li>\n",
    "   <li> The correlation matrix between all pairs of attributes has been calculated to visualize their dependencies. The results achieved report that total_rooms, total_bedrooms, population and households are highly (positive) correlated.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">After this phase of data preparation, a final dataset of 20,433 instances are obtained with 8 attributes (InputsMedianHouseValueNormalized.csv): $longitude$ and $latitude$ (location), $median age$, $total rooms$, $total bedrooms$, $population$, $households$ and $median income$. The last will be our label. </div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">From this data, the classification problem consists on estimating the median house value, categorized into the following 10 clases (price intervals in thousand dollards): [15.0, 82.3], [82.4, 107.3], [107.4, 133.9], [134.0, 157.3], [157.4, 179.7], [179.8, 209.4], [209.5, 241.9], [242.0, 290.0], [290.1, 376.6] and [376.7, 500.0]. Each class is labelled from 0 (the cheapest) to 9 (the most expensive), and one-hot encoded in <b>MedianHouseValueOneHotEncodedClasses.csv</b> file.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Design process\n",
    "\n",
    "## 2.1 Installation\n",
    "<br>\n",
    "<div style=\"text-align: justify\">We have decided to use Anaconda as our programming environment. The installation process was as follows: </div>\n",
    "\n",
    "<ol type=\"1\" style=\"text-align: justify\">\n",
    "   <li> <b> Anaconda download and installation </b>, we downloaded Anaconda from the official webpage (https://www.anaconda.com/distribution/) and installed it following the steps of the program.</li>\n",
    "   <li> <b> Environment creation </b> we created a separated environment called tf-gpu for installing the libraries and we added it to jupyter</li>\n",
    "   <li> <b> Libraries installation </b>, after that, we installed the following libraries used in the notebook:  </li>  \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} tensorflow-gpu\n",
    "!conda install --yes --prefix {sys.prefix} keras-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"4\" style=\"text-align: justify\">\n",
    "     <li><b>Test of tensorflow</b>, after the installation we executed the test program provided in class (matrix multiplication) in order to check that tensorflow was working properly</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Process followed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the development process we focused on using the approach discussed in class:\n",
    "<img src=\"Images/Im2.png\" style=\"width: 45%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">In order to achieve this, we structured the develoment process in three stages:</div>\n",
    "<br>\n",
    "<ol type=\"1\" style=\"text-align: justify\">\n",
    "   <li> <b>Models search</b>, in this stage, we executed around 200 models with different architectures and parameters, in order to compare which approaches give better results. We analyzed the outputs using tensorboard. </li>\n",
    "   <li> <b> Models choice</b>, we selected the 5 best models according to the test accuracy and we re-executed them with a higher number of epochs. After that we saved the models. </li>\n",
    "   <li> <b> Ensemble method</b>, using the models obtained in the previous step, we constructed a ensemble network in order to check if it gave a better result </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Models search\n",
    "<br>\n",
    "<div style=\"text-align: justify\">We explored different combinations of models with different architectures and hyperparameters:</div>\n",
    "\n",
    "<ul style=\"text-align: justify\">\n",
    "   <li> <b>Activation functions tried</b>: softmax, sigmoid, Hyperbolic tangent, ReLu, ELU, Leaky Relu</li>\n",
    "   <li> <b>Loss functions tried</b>: Sigmoid cross-entropy, Softmax cross-entropy</li>\n",
    "   <li> <b>Training techniques tried</b>: Gradient descent, Momentum, RMSprop</li>\n",
    "   <li> <b>Normalization techniques tried</b> (without taking into account the changes made to the inputs): Dropout, Weights inizialization (Zero, random uniform, random normal, Xavier uniform, Xavier normal)</li>\n",
    "   <li> <b>DL Architectures tried</b>: (500, 300, 300, 150,75,25,10),(300,150,75,25,10), (100,300,500,400,200,100,50,10), (150,75,25,10),(300,150,75,10)</li>\n",
    "   <li> <b>Parameters tried</b>: Learning rate (0.1,0.01,0.001,0.0001), batch size (16-32-100-200) and random</li>\n",
    "   <li> <b>Metric used</b>: loss and accuracy  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the following libraries for the code developed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The main function used is below, we input the different paramters to create_run_model, then we create the graph for the network and run the model. The inputs are:</div>\n",
    "\n",
    "<ul style=\"text-align: justify\">\n",
    "   <li> <b>Inputs</b>: Number of inputs of the network (integer).</li>\n",
    "   <li> <b>Outputs</b>: Number of outputs of the network (integer).</li>\n",
    "   <li> <b>Learning rate</b>: for the training algorithm (float).</li>\n",
    "   <li> <b>n_neurons</b>: Array of integers with the number of neurons per layer (the number of layers is the lenght of this array) (Array).</li>\n",
    "   <li> <b>batch_norm</b>: boolean, if true batch normalization is applied on each layer.</li>\n",
    "   <li> <b>dropout</b>: boolean, if true batch normalization is applied on each layer.</li>\n",
    "   <li> <b>optimizer</b>: string, type of optimizer to use on each layer. Possible values (\"relu\", \"elu\", \"leakyrelu\", \"softmax\", \"sigmoid\", \"tanh\").</li>\n",
    "   <li> <b>initb</b>: string, way of initialize the bias, possible values (\"zero\", \"const\"), the const is with value 0.1.</li>\n",
    "   <li> <b>initw</b>: string, way of initialize the weights, possible values (\"Xavier_Normal\", \"Xavier_Uniform\",\"RUniform\",  \"RNormal\", \"TNormal\"). The Uniform is between (-0.5, 0.5) and the normal has mean 0 and stdev 0.5.</li>\n",
    "   <li> <b>l2</b>: boleean, if true L2 normalization is applied.</li>\n",
    "   <li> <b>writter_train</b>: writter for recording the train values for display them in tensorboard.</li>\n",
    "   <li> <b>writter_test</b>: writter for recording the test values for display then in tensorboard.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_run_model(inputs, outputs, learning_rate, n_neurons, \n",
    "                     batch_norm, activation, loss_fun, \n",
    "                     dropout,optimizer, initb, initw, \n",
    "                     l2, writer_train, writer_test):\n",
    "    \n",
    "    g = create_graph(inputs, outputs, learning_rate, n_neurons,batch_norm,\n",
    "                     activation, loss_fun, dropout, optimizer, initb, initw, l2)\n",
    "    \n",
    "    run_model(writer_train, writer_test, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The graph is created with the function below, the structure is the following:</div>\n",
    "\n",
    "<ol type=\"1\" style=\"text-align: justify\">   \n",
    "   <li> Create an empty graph.</li>\n",
    "   <li> Define the inputs to the graph.</li>\n",
    "   <li> Define the hidden layers and its activations functions.</li>\n",
    "   <li> Define loss function.</li>\n",
    "   <li> Define optimizer.</li>\n",
    "   <li> Define the accuracy.</li>\n",
    "   <li> Define logs for tensorboard and variables to use in the train step.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(inputs, outputs, learning_rate, n_neuron,batch_norm, activation, \n",
    "                 loss_fun, dropout, optimizer, initb, initw, l2):\n",
    "    # 1. Create an empty graph\n",
    "\n",
    "    g1 = tf.Graph()\n",
    "    with g1.as_default() as g:\n",
    "        \n",
    "        # 2. Define the inputs to the graph\n",
    "        \n",
    "        training = tf.placeholder_with_default (False, shape=(), name = \"training\") #for batch norm.\n",
    "        X = tf.placeholder (dtype=tf.float32, shape=(None,inputs),name=\"X\")  #Data\n",
    "        t = tf.placeholder (dtype=tf.float32, shape=(None,outputs), name=\"Labels\")  #Labels\n",
    "\n",
    "        # 3. Define the hidden layers and its activations functions\n",
    "        \n",
    "        w = []\n",
    "        hidden_layers = []\n",
    "        layers_temp, w_temp = dense_layer(X,inputs, n_neurons[0], batch_norm, activation, dropout,\\\n",
    "                                          training, initb, initw)\n",
    "        \n",
    "        hidden_layers.append(layers_temp)\n",
    "        w.append(w_temp)\n",
    "        \n",
    "        for layer in range(1,len(n_neurons)):\n",
    "            layers_temp, w_temp = dense_layer(hidden_layers[layer-1],\n",
    "                                             n_neurons[layer-1],\n",
    "                                             n_neurons[layer],\n",
    "                                             batch_norm, activation, dropout, \\\n",
    "                                             training, initb, initw)\n",
    "            hidden_layers.append(layers_temp)\n",
    "            w.append(w_temp)\n",
    "\n",
    "        layers_temp, w_temp = dense_layer(hidden_layers[len(n_neurons)-1],\n",
    "                                          n_neurons[-1],\n",
    "                                          outputs,False, \"None\", False, training, initb, initw)\n",
    "        net_out = layers_temp\n",
    "        w.append(w_temp)\n",
    "\n",
    "        y = tf.nn.softmax(logits=net_out, name=\"y\")\n",
    "\n",
    "        # 4. Define loss function\n",
    "        \n",
    "        beta = 0.01\n",
    "        with tf.name_scope(\"Cost\"):\n",
    "            if loss_fun == \"softmax\":\n",
    "                cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=t,logits=net_out)\n",
    "            elif loss_fun == \"sigmoid\":\n",
    "                cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=t, logits=net_out)\n",
    "            # Loss function with L2 Regularization with beta=0.01\n",
    "            if l2 == True:\n",
    "                regularizers =tf.nn.l2_loss(w[0])\n",
    "                for i in range(1,len(w)):\n",
    "                    regularizers =  regularizers + tf.nn.l2_loss(w[i])\n",
    "                mean_log_loss=tf.reduce_mean(cross_entropy+beta*regularizers,name=\"mean_log_loss\")    \n",
    "            else:\n",
    "                mean_log_loss = tf.reduce_mean (cross_entropy, name=\"mean_log_loss\")\n",
    "            \n",
    "        # 5. Define optimizer\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "            if optimizer == \"Adam\":\n",
    "                train_step = tf.train.AdamOptimizer(learning_rate).minimize(mean_log_loss)\n",
    "            elif optimizer == \"RMSPROP\":\n",
    "                train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(mean_log_loss)\n",
    "            elif optimizer == \"momentum\":\n",
    "                train_step = tf.train.MomentumOptimizer(learning_rate,0.9).minimize(mean_log_loss)\n",
    "            elif optimizer == \"gradient_desc\":\n",
    "                train_step =tf.train.GradientDescentOptimizer(learning_rate).minimize(mean_log_loss)\n",
    "\n",
    "        # 6 Define Accuracy\n",
    "        \n",
    "        with tf.name_scope(\"Evaluation\"):\n",
    "            correct_predictions = tf.equal(tf.argmax(y,1),tf.argmax(t,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_predictions,tf.float32))\n",
    "            \n",
    "        # 7 Define logs for tensorboard and variables to use in the train step\n",
    "\n",
    "        tf.summary.scalar(\"cross_entropy\", mean_log_loss)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "        merged_summary = tf.summary.merge_all()\n",
    "\n",
    "        g.add_to_collection(\"elements\", training)\n",
    "        g.add_to_collection(\"elements\", X)\n",
    "        g.add_to_collection(\"elements\", t)\n",
    "        g.add_to_collection(\"elements\", y)\n",
    "        g.add_to_collection(\"elements\", mean_log_loss)\n",
    "        g.add_to_collection(\"elements\", train_step)\n",
    "        g.add_to_collection(\"elements\", correct_predictions)\n",
    "        g.add_to_collection(\"elements\", accuracy)\n",
    "        g.add_to_collection(\"elements\", merged_summary)\n",
    "        \n",
    "    return g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">We use the following function for create each hidden layer cell. It uses the inputs already explained in the previous functions. The structure is the following:</div>\n",
    "\n",
    "<ol type=\"1\" style=\"text-align: justify\"> \n",
    "   <li> Weigts definition\n",
    "   <li> Bias definition</li>\n",
    "   <li> Activation definition</li>\n",
    "   <li> Regularization techiques. We have tried batch normalization before the activation function</li>\n",
    "   <li> Logs creation </li>\n",
    "</ol>\n",
    "<div style=\"text-align: justify\">We use batch normalization and then dropout (both after the activation function after researching about the topic.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Im20.png\" style=\"width: 100%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(input, channels_in, channels_out, batch_norm, activation, dropout, training, initb, initw, name=\"dense\"):\n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        # 1. Weights definition \n",
    "        \n",
    "        if initw == \"RUniform\":\n",
    "            w = tf.Variable(tf.random_uniform([channels_in, channels_out],\\\n",
    "                                              minval=-0.5, maxval = 0.5),name = \"W\")\n",
    "        elif initw == \"Xavier_Normal\":\n",
    "            w = tf.Variable(tf.glorot_normal_initializer()((channels_in, channels_out)),name = \"W\")\n",
    "        elif initw == \"Xavier_Uniform\":\n",
    "            w = tf.Variable(tf.glorot_uniform_initializer()((channels_in, channels_out)),name = \"W\")\n",
    "        elif initw == \"RNormal\":\n",
    "            w = tf.Variable(tf.random_normal([channels_in, channels_out], stddev=0.5),name = \"W\")\n",
    "        elif initw == \"TNormal\":\n",
    "            w = tf.Variable(tf.truncated_normal([channels_in, channels_out], stddev=0.5),name = \"W\")\n",
    "\n",
    "        # 2. Bias definition\n",
    "        \n",
    "        if initb == \"zero\":\n",
    "            b = tf.Variable(tf.constant(0.1, shape = [channels_out]), name = \"b\")\n",
    "        elif initb == \"const\":\n",
    "            b = tf.Variable(tf.zeros(shape = [channels_out]), name = \"b\")\n",
    "            \n",
    "        # 3. Actication definition\n",
    "        \n",
    "        prev_layer = input\n",
    "        \n",
    "        if batch_norm:\n",
    "            prev_layer = tf.layers.batch_normalization(prev_layer, training=training) \n",
    "            \n",
    "        if activation == \"relu\":\n",
    "            prev_layer = tf.nn.relu(tf.matmul(prev_layer, w) + b)\n",
    "        elif activation == \"elu\":\n",
    "            prev_layer = tf.nn.elu(tf.matmul(prev_layer, w) + b)\n",
    "        elif activation == \"leakyrelu\":\n",
    "            prev_layer = tf.nn.leaky_relu(tf.matmul(prev_layer, w) + b)\n",
    "        elif activation == \"softmax\":\n",
    "            prev_layer = tf.nn.softmax(tf.matmul(prev_layer, w) + b)\n",
    "        elif activation == \"sigmoid\":\n",
    "            prev_layer = tf.nn.sigmoid(tf.matmul(prev_layer, w) + b)\n",
    "        elif activation == \"tanh\":\n",
    "            prev_layer = tf.nn.tanh(tf.matmul(prev_layer, w) + b)\n",
    "\n",
    "        # 4. Regularization techniques\n",
    "        \n",
    "        if dropout:\n",
    "            prev_layer = tf.nn.dropout(prev_layer, rate = 0.25)\n",
    "        \n",
    "        # 4. Logs creation\n",
    "        \n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"bias\", b)\n",
    "        tf.summary.histogram(\"act\", prev_layer)\n",
    "        \n",
    "        return prev_layer, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Finally we run the model for training with the following function:</div>\n",
    "<ol type=\"1\" style=\"text-align: justify\"> \n",
    "   <li> Paramaters definition</li>\n",
    "   <li> Graph initialization</li>\n",
    "   <li> Retrieve elements used from graph</li>\n",
    "   <li> Define the feeds for each call</li>\n",
    "   <li> Loop for training</li>\n",
    "   <li> Logs for tensorboard</li>\n",
    "   <li> Evaluation metrics </li>\n",
    "</ol>  \n",
    "<div style=\"text-align: justify\">We used different values for epochs and batch size for the different models (and fixed batch vs random batch selection also), although here they are fixed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(writer_test, writer_train, g):\n",
    "    \n",
    "    # 1. Parameters definition\n",
    "    \n",
    "    accuracy_train_history = []\n",
    "    n_epochs = 30000\n",
    "    batch_size = 400\n",
    "\n",
    "    \n",
    "    # 2. Graph initialization\n",
    "    \n",
    "    with tf.Session(graph = g) as sess:\n",
    "        \n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # This parameter is activated when we want ot save the session for load it later\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        writer_train.add_graph(sess.graph)\n",
    "        writer_test.add_graph(sess.graph)\n",
    "        \n",
    "        # 3. Retrieve elements used from graph\n",
    "        \n",
    "        training, X, t, y, mean_log_loss, train_step, \\\n",
    "        correct_predictions, accuracy, merged_summary = g.get_collection(\"elements\")\n",
    "\n",
    "        # 4. Define the feeds for each call\n",
    "        \n",
    "        test_feed = {training: False, X: x_test[:NUM_TEST_EXAMPLES],\\\n",
    "                                         t: t_test[:NUM_TEST_EXAMPLES]}\n",
    "        train_feed = {training: False, X: x_train[:NUM_TRAINING_EXAMPLES], \\\n",
    "                                          t: t_train[:NUM_TRAINING_EXAMPLES]}\n",
    "        \n",
    "        # 5. Loop for training\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            offset = np.random.randint(0,NUM_TRAINING_EXAMPLES,300)\n",
    "\n",
    "            feed = {training: True, X: x_train[offset], t: t_train[offset]}\n",
    "            feed_eval = {training: False, X: x_train[offset], t: t_train[offset]}\n",
    "\n",
    "            # 6. Logs for tensorboard\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                s_train = sess.run(merged_summary, feed_dict=feed_eval)\n",
    "                s_test = sess.run(merged_summary, feed_dict=test_feed)\n",
    "                writer_train.add_summary(s_train,epoch)\n",
    "                writer_test.add_summary(s_test,epoch)\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                train_accuracy = sess.run(accuracy, feed_dict=feed_eval)\n",
    "                test_accuracy = sess.run(accuracy, feed_dict=test_feed)\n",
    "                print(\"step %d, training accuracy %g, test accuracy %g\" % \\\n",
    "                      (epoch, train_accuracy, test_accuracy))     \n",
    "\n",
    "            sess.run (train_step, feed_dict=feed)\n",
    "        \n",
    "        # 7. Evaluation metrics\n",
    "        \n",
    "        accuracy_test = accuracy.eval(feed_dict=test_feed)\n",
    "        accuracy_train = accuracy.eval(feed_dict=train_feed)\n",
    "\n",
    "        test_predictions = y.eval(feed_dict={X: x_test[:NUM_TEST_EXAMPLES]})\n",
    "        test_correct_preditions = correct_predictions.eval (feed_dict=test_feed)\n",
    "\n",
    "        train_mean_log_loss = mean_log_loss.eval(feed_dict = test_feed)\n",
    "        test_mean_log_loss = mean_log_loss.eval(feed_dict = test_feed)\n",
    "        \n",
    "        # This is activated when we want to save the model\n",
    "        saver.save(sess, \"/TF_Models/Batch/Batch.ckpt\")\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">With this function now we launch our search, first we read the data:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (16346, 8)\n",
      "t_train: (16346, 10)\n",
      "x_dev: (2043, 8)\n",
      "t_dev: (2043, 10)\n",
      "x_test: (2044, 8)\n",
      "t_test: (2044, 10)\n"
     ]
    }
   ],
   "source": [
    "run 1.ReadingData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = x_train.shape[1]\n",
    "OUTPUTS = t_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(x_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int (round (x_dev.shape[0]/1))\n",
    "NUM_TEST_EXAMPLES = int (round (x_test.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">We define one more function for creating an string for naming the folders created for tensorflow (and so be able to query them using regex expressions), we basically input all the parameters used and concatenate them:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hparam_string(initb, initw, learning_rate, n_neurons, batch_norm, optimizer, activation, loss_fun, dropout, l2):\n",
    "    \n",
    "    output = \"learning_rate = \" + str(learning_rate) + \", neurons = \" + str(n_neurons) + \\\n",
    "            \", batch_norm =\" + str(batch_norm) + \", opt = \" + str(optimizer) + \\\n",
    "            \", act = \" + str(activation) + \\\n",
    "            \", loss = \" + str(loss_fun) + \", drop = \" + str(dropout) + \\\n",
    "            \", binit = \" + str(initb) + \\\n",
    "            \", winit = \" + str(initw) + \", l2 = \" + str(l2)\n",
    "    \n",
    "    return  output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">We also have to define the parameters, we include all the parameters we tried below, although we didn´t tried all the combinations for computing time reasons:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = [\"Adam\", \"RMSPROP\", \"momentum\", \"gradient_desc\"]\n",
    "act = [\"relu\", \"elu\", \"leakyrelu\", \"softmax\", \"sigmoid\", \"tanh\"]\n",
    "loss = [\"softmax\", \"sigmoid\"]\n",
    "BInit = [\"zero\", \"const\"]\n",
    "WInit = [\"Xavier_Normal\", \"Xavier_Uniform\",\"RUniform\",  \"RNormal\", \"TNormal\"]\n",
    "batch_norm = [True, False]\n",
    "dropout = [True, False]\n",
    "l2 = [True, False]\n",
    "rates = [1E-1, 1E-2, 1E-3, 1E-4]\n",
    "neurons = [[500, 300, 300, 150,75,25,10],[300,150,75,25,10], \\\n",
    "           [100,300,500,400,200,100,50,10], [150,75,25,10],[300,150,75]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Finally we run the different models (again although its displayed like these, we selected different combinations of the parameters above for the different runs we did), basically we:</div>\n",
    "<ol type=\"1\" style=\"text-align: justify\"> \n",
    "   <li> Initialize the loop</li>\n",
    "   <li> Create the folder string</li>\n",
    "   <li> Print the model for log purposes</li>\n",
    "   <li> Create the tensorboard writters</li>\n",
    "   <li> Create and run the model</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(INPUTS,OUTPUTS, learning_rate,n_neurons, \\\n",
    "        batch_norm,activation, \\\n",
    "        loss_fun,dropout,\\\n",
    "        optimizer,initb, \\\n",
    "        initw, l2,i)\n",
    "    \n",
    "    # 2. Create the folder string\n",
    "\n",
    "    hparam_str = make_hparam_string(initb, initw, \\\n",
    "                                    learning_rate,\\\n",
    "                                    n_neurons, batch_norm, \\\n",
    "                                    optimizer, activation, \\\n",
    "                                    loss_fun, dropout, l2)\n",
    "\n",
    "    # 3. Print the model for log purposes\n",
    "\n",
    "    print(\"----------------------------\")\n",
    "    print(\"MODEL \" + hparam_str)\n",
    "    print(\"----------------------------\")      \n",
    "\n",
    "    # 4. Create the tensorboard writters\n",
    "\n",
    "    writer_train = tf.summary.FileWriter(\"/TF_Logs/20190904/\"\\\n",
    "                                         + str(i) + \" Train \" + \\\n",
    "                                         hparam_str)\n",
    "    writer_test = tf.summary.FileWriter(\"/TF_Logs/20190904/\" \\\n",
    "                                        + str(i) + \" Test \" + \\\n",
    "                                        hparam_str)\n",
    "\n",
    "    # 5. Create and run the model\n",
    "\n",
    "    create_run_model(INPUTS,OUTPUTS, learning_rate,n_neurons, \\\n",
    "                     batch_norm,activation,loss_fun,dropout,optimizer, \\\n",
    "                     initb, initw, l2, writer_test,writer_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable is for ordering the folders that are created\n",
    "i = 0\n",
    "\n",
    "# 1. Initialize the loop\n",
    "\n",
    "for optimizer in [\"Adam\"]:\n",
    "    for activation in [\"elu\"]:\n",
    "        for loss_fun in [\"softmax\"]:\n",
    "            for initb in BInit:\n",
    "                for initw in WInit:\n",
    "                    for batch_norm in [False]:\n",
    "                        for dropout in [False]:\n",
    "                            for learning_rate in rates:\n",
    "                                for n_neurons in neurons:\n",
    "                                    i = i + 1\n",
    "                                    run(INPUTS,OUTPUTS, \\\n",
    "                                        learning_rate,n_neurons, \\\n",
    "                                        batch_norm,activation, \\\n",
    "                                        loss_fun,dropout,\\\n",
    "                                        optimizer,initb, \\\n",
    "                                        initw, l2,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The strategy followed during the search was executing a large number of models with low epochs and non-random batch size at the beggining in order to check if the model improve and how quickly. After that we selected the parameters that worked better for a second execution with less models but more epochs. Finally we executed a small number of models with more epochs and specific parameters.</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">The cmd code used to execute tensorboard is (remember that the logs are stored in the path were jupyter is executed):</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir /logs/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">So as we stated in the first execution we obtained arond 120 models:</div>\n",
    "\n",
    "<img src=\"Images/Im12.png\" style=\"width: 45%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">We analyzed the results with tensorflow, using regex to filter the results</div>\n",
    "\n",
    "<img src=\"Images/Im4.png\" style=\"width: 20%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> here we can see the best 11 models with 2000 epochs (showing only test results):</div>\n",
    "\n",
    "<img src=\"Images/Im3.png\" style=\"width: 65%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The best results were obtained with the following parameters with a test accuracy of 0.2236 and train accuracy 0.2233 after 2.000 epochs:</div>\n",
    "\n",
    "<ul style=\"text-align: justify\">\n",
    "    <li>learning_rate = 0.0001</li>\n",
    "    <li>neurons = [500, 300, 300, 150, 75, 25, 10]</li>\n",
    "    <li>batch_norm =False</li>\n",
    "    <li>opt = Adam</li>\n",
    "    <li>act = elu</li>\n",
    "    <li>loss = sigmoid</li>\n",
    "    <li>drop = False</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Using tensorboard we can also see how the weights evolve over time and the difference between different inizialization methods. For example, below we can see how the bias of two different models evolve over time (initialized in 0.1) and the difference in the weights of the last layer and the first (initialized with random normal), we can see how the last layer is more updated and the first layer remains normal (due to the low epochs applied):</div>\n",
    "\n",
    "<img src=\"Images/Im13.png\" style=\"width: 45%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">We can also see the graphs structures of the different models (left example with batch normalization and right without):</div>\n",
    "\n",
    "<img src=\"Images/Im14.png\" style=\"width: 45%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">And we can zoom to see inside (for example to see the dropout):</div>\n",
    "\n",
    "<img src=\"Images/Im7.png\" style=\"width: 45%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">In summary, after that, we executed again using 4000 epochs, the parameters that gave better results and some more. We obtained for the best model a test accuracy of 0.4193 and train accuracy of 0.38 (we display only test results)</div>\n",
    "\n",
    "<img src=\"Images/Im15.png\" style=\"width: 45%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The parameters used for the best model were:</div>\n",
    "<ul style=\"text-align: justify\">\n",
    "    <li>learning_rate = 0.001</li>\n",
    "    <li>neurons = [300, 150, 75, 25, 10]</li>\n",
    "    <li>batch_norm =False</li>\n",
    "    <li>opt = Adam</li>\n",
    "    <li>act = elu</li>\n",
    "    <li>loss = softmax</li>\n",
    "    <li>drop = False</li>\n",
    "    <li>binit = const</li>\n",
    "    <li>drop = Xavier_Uniform</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">And finally we executed some models for a much large number of epochs (16.000), obtaining the following test resutls:</div>\n",
    "\n",
    "<img src=\"Images/Im17.png\" style=\"width: 45%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The best model regarding test achieved 0.4697 in test set and 0.6367 in train. The best model regarding train achieved 0.76 in train, although 0.4525 in test set. If we have a look at the graph of this model we can see that its overfitting mor or less since epoch 4.000: </div>\n",
    "\n",
    "\n",
    "<img src=\"Images/Im16.png\" style=\"width: 45%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Models Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we selected the 5 models that gave us better results and we reexecuted them again, saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_execution(optimizer,activation,loss_fun,initb,\n",
    "                    initw,batch_norm,dropout,l2,learning_rate,n_neurons,i)\n",
    "\n",
    "    hparam_str = make_hparam_string(initb, initw, \\\n",
    "                                    learning_rate,\\\n",
    "                                    n_neurons, batch_norm, \\\n",
    "                                    optimizer, activation, \\\n",
    "                                    loss_fun, dropout, l2)\n",
    "\n",
    "    print(\"----------------------------\")\n",
    "    print(\"MODEL \" + hparam_str)\n",
    "    print(\"----------------------------\")      \n",
    "\n",
    "    writer_train = tf.summary.FileWriter(\"/TF_Logs/20190904/\"\\\n",
    "                                         + str(i) + \" Train \" + \\\n",
    "                                         hparam_str)\n",
    "    writer_test = tf.summary.FileWriter(\"/TF_Logs/20190904/\" \\\n",
    "                                        + str(i) + \" Test \" + \\\n",
    "                                        hparam_str)\n",
    "\n",
    "    create_run_model(INPUTS,OUTPUTS, learning_rate,n_neurons, \\\n",
    "                     batch_norm,activation,loss_fun,dropout,optimizer, \\\n",
    "                     initb, initw, l2, writer_test,writer_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeated the above code for the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 1 - Overfitted best result (train 0.96 - 50K epochs - Train 0.94 - Test 0.42)\n",
    "optimizer = \"Adam\"\n",
    "activation = \"elu\"\n",
    "loss_fun = \"softmax\"\n",
    "initb = \"const\"\n",
    "initw = \"Xavier_Normal\"\n",
    "batch_norm = False\n",
    "dropout = False\n",
    "l2 = False\n",
    "learning_rate = 1E-3\n",
    "n_neurons = [500, 300, 300, 150,75,25,10]\n",
    "i = 0\n",
    "\n",
    "model_execution(optimizer,activation,loss_fun,initb,\n",
    "                    initw,batch_norm,dropout,l2,learning_rate,n_neurons,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2 - Best test result (without overfitting) (9.5K epochs - Train 0.61 - Test 0.44) \n",
    "optimizer = \"Adam\"\n",
    "activation = \"elu\"\n",
    "loss_fun = \"softmax\"\n",
    "initb = \"const\"\n",
    "initw = \"Xavier_Normal\"\n",
    "batch_norm = False\n",
    "dropout = False\n",
    "l2 = False\n",
    "learning_rate = 1E-3\n",
    "n_neurons = [500, 300, 300, 150,75,25,10]\n",
    "\n",
    "i = 2\n",
    "\n",
    "model_execution(optimizer,activation,loss_fun,initb,\n",
    "                    initw,batch_norm,dropout,l2,learning_rate,n_neurons,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3 - 2nd best test result (20K epochs - Train 0.53 - Test 0.45)\n",
    "optimizer = \"Adam\"\n",
    "activation = \"elu\"\n",
    "loss_fun = \"softmax\"\n",
    "initb = \"const\"\n",
    "initw = \"Xavier_Uniform\"\n",
    "batch_norm = False\n",
    "dropout = False\n",
    "l2 = False\n",
    "learning_rate = 1E-3\n",
    "n_neurons = [300, 150, 75, 25, 10]\n",
    "\n",
    "i = 3\n",
    "\n",
    "model_execution(optimizer,activation,loss_fun,initb,\n",
    "                    initw,batch_norm,dropout,l2,learning_rate,n_neurons,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 4 - Best dropout result (120K epochs - Train 0.35 - Test 0.36)\n",
    "optimizer = \"Adam\"\n",
    "activation = \"relu\"\n",
    "loss_fun = \"softmax\"\n",
    "initb = \"const\"\n",
    "initw = \"Xavier_Normal\"\n",
    "batch_norm = False\n",
    "dropout = True\n",
    "l2 = False\n",
    "learning_rate = 1E-4\n",
    "n_neurons = [300, 150, 75, 25, 10]\n",
    "\n",
    "i = 4\n",
    "\n",
    "model_execution(optimizer,activation,loss_fun,initb,\n",
    "                    initw,batch_norm,dropout,l2,learning_rate,n_neurons,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 5 - Best l2 result (30K epochs - Train 0.33 - Test 0.31)\n",
    "optimizer = \"RMSPROP\"\n",
    "activation = \"elu\"\n",
    "loss_fun = \"softmax\"\n",
    "initb = \"const\"\n",
    "initw = \"Xavier_Normal\"\n",
    "batch_norm = False\n",
    "dropout = False\n",
    "l2 = True\n",
    "learning_rate = 1E-3\n",
    "n_neurons = [300, 150, 75, 25, 10]\n",
    "\n",
    "i = 5\n",
    "\n",
    "model_execution(optimizer,activation,loss_fun,initb,\n",
    "                    initw,batch_norm,dropout,l2,learning_rate,n_neurons,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving all the models we reload them and perform the ensemble method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(Path, name):\n",
    "    tf.reset_default_graph()\n",
    "    # Later, launch the model, use the saver to restore variables from disk, and\n",
    "    # do some work with the model.\n",
    "    with tf.Session() as sess:\n",
    "        new_saver = tf.train.import_meta_graph( Path + name + '.ckpt.meta')\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint(Path))\n",
    "        g = tf.get_default_graph()\n",
    "        training, X, t, y, mean_log_loss, train_step, \\\n",
    "        correct_predictions, accuracy, merged_summary = g.get_collection(\"elements\")\n",
    "        \n",
    "        # Check the values of the variables\n",
    "        predictions_test = y.eval(feed_dict={X: x_test[:NUM_TEST_EXAMPLES]})\n",
    "        predictions_dev = y.eval(feed_dict={X: x_dev[:NUM_TEST_EXAMPLES]})\n",
    "        predictions_train = y.eval(feed_dict={X: x_train[:NUM_TEST_EXAMPLES]})\n",
    "        \n",
    "        sess.close()\n",
    "    return predictions_test, predictions_dev, predictions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test1, p_dev1, p_train1 = get_pred(\"/TF_Models/Overfit/\", \"Overfit\")\n",
    "p_test2, p_dev2, p_train2 = get_pred(\"/TF_Models/Best/\", \"Best\")\n",
    "p_test3, p_dev3, p_train3 = get_pred(\"/TF_Models/2ndBest/\", \"2ndBest\")\n",
    "p_test4, p_dev4, p_train4 = get_pred(\"/TF_Models/Dropout/\", \"Dropout\")\n",
    "p_test5, p_dev5, p_train5 = get_pred(\"/TF_Models/L2/\", \"L2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Option 1: Average of the results </b>\n",
    "\n",
    "We calculate the average of the results as the final result, we can see that the accuracy did not improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train = np.mean([p_train1, p_train1, p_train1, p_train1, p_train1], axis=0)\n",
    "avg_test = np.mean([p_test1, p_test1, p_test1, p_test1, p_test1], axis=0)\n",
    "avg_dev = np.mean([p_dev1, p_dev1, p_dev1, p_dev1, p_dev1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([t_test[i].argmax() for i in range(avg_test.shape[0])])\n",
    "train = np.array([t_train[i].argmax() for i in range(avg_train.shape[0])])\n",
    "dev = np.array([t_dev[i].argmax() for i in range(avg_dev.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = np.array([avg_train[i].argmax() for i in range(avg_train.shape[0])])\n",
    "result_test = np.array([avg_test[i].argmax() for i in range(avg_test.shape[0])])\n",
    "result_dev = np.array([avg_dev[i].argmax() for i in range(avg_dev.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8918786692759295\n",
      "Test accuracy: 0.4207436399217221\n",
      "Dev accuracy: 0.44591287322564854\n"
     ]
    }
   ],
   "source": [
    "train_result = np.equal(train, result_train)\n",
    "test_result = np.equal(test, result_test)\n",
    "dev_result = np.equal(dev, result_dev)\n",
    "print(\"Train accuracy: \" + str(np.average(train_result)))\n",
    "print(\"Test accuracy: \" + str(np.average(test_result)))\n",
    "print(\"Dev accuracy: \" + str(np.average(dev_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Option 2: Voting system </b>\n",
    "\n",
    "We calculate the resul of each network and perform a voting system, choosing model 3 or model 2 in case of draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = np.array([p_train1[i].argmax() for i in range(avg_train.shape[0])])\n",
    "train2 = np.array([p_train2[i].argmax() for i in range(avg_train.shape[0])])\n",
    "train3 = np.array([p_train3[i].argmax() for i in range(avg_train.shape[0])])\n",
    "train4 = np.array([p_train4[i].argmax() for i in range(avg_train.shape[0])])\n",
    "train5 = np.array([p_train5[i].argmax() for i in range(avg_train.shape[0])])\n",
    "\n",
    "test1 = np.array([p_test1[i].argmax() for i in range(avg_test.shape[0])])\n",
    "test2 = np.array([p_test2[i].argmax() for i in range(avg_test.shape[0])])\n",
    "test3 = np.array([p_test3[i].argmax() for i in range(avg_test.shape[0])])\n",
    "test4 = np.array([p_test4[i].argmax() for i in range(avg_test.shape[0])])\n",
    "test5 = np.array([p_test5[i].argmax() for i in range(avg_test.shape[0])])\n",
    "\n",
    "dev1 = np.array([p_dev1[i].argmax() for i in range(avg_dev.shape[0])])\n",
    "dev2 = np.array([p_dev2[i].argmax() for i in range(avg_dev.shape[0])])\n",
    "dev3 = np.array([p_dev3[i].argmax() for i in range(avg_dev.shape[0])])\n",
    "dev4 = np.array([p_dev4[i].argmax() for i in range(avg_dev.shape[0])])\n",
    "dev5 = np.array([p_dev5[i].argmax() for i in range(avg_dev.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_voting = np.array([train1, train2, train3, train4, train5])\n",
    "test_voting = np.array([test1, test2, test3, test4, test5])\n",
    "dev_voting = np.array([dev1, dev2, dev3, dev4, dev5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_calc(inp_array):\n",
    "    final = np.array([])\n",
    "\n",
    "    for i in range(inp_array.shape[1]):\n",
    "        \n",
    "        occurances = np.bincount(inp_array[:,i])\n",
    "        \n",
    "        if len(np.where(occurances == np.max(occurances)))>1:\n",
    "            if np.isin(inp_array[:,i][3],np.where(occurances == 2)):\n",
    "                \n",
    "                final = np.append(final,inp_array[:,i][3])\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                final = np.append(final,inp_array[:,i][2])\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            final = np.append(final,np.argmax(occurances))\n",
    "            \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = voting_calc(train_voting)\n",
    "final_test = voting_calc(test_voting)\n",
    "final_dev = voting_calc(dev_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6643835616438356\n",
      "Test accuracy: 0.6453033268101761\n",
      "Dev accuracy: 0.6441507586882036\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \" + str(np.mean(np.equal(final_train, result_train))))\n",
    "print(\"Test accuracy: \" + str(np.mean(np.equal(final_test, result_test))))\n",
    "print(\"Dev accuracy: \" + str(np.mean(np.equal(final_dev, result_dev))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we improved the results in a considerable way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Since we were working with the test set since the beggining when developing the models, we use the t_test and x_test as development sets and x_dev as final test sets.</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">In this section we are going to present the final results (Train-Test-Dev) for each of the 5 models selected and the ensemble.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Model 1 - Overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8918786692759295\n",
      "Test accuracy: 0.4207436399217221\n",
      "Dev accuracy: 0.44591287322564854\n"
     ]
    }
   ],
   "source": [
    "result_train =  np.array([p_train1[i].argmax() for i in range(p_train1.shape[0])])\n",
    "result_test = np.array([p_test1[i].argmax() for i in range(p_test1.shape[0])])\n",
    "result_dev = np.array([p_dev1[i].argmax() for i in range(p_dev1.shape[0])])\n",
    "\n",
    "train_result = np.equal(train, result_train)\n",
    "test_result = np.equal(test, result_test)\n",
    "dev_result = np.equal(dev, result_dev)\n",
    "\n",
    "print(\"Train accuracy: \" + str(np.average(train_result)))\n",
    "print(\"Test accuracy: \" + str(np.average(test_result)))\n",
    "print(\"Dev accuracy: \" + str(np.average(dev_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Model 2 - Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5758317025440313\n",
      "Test accuracy: 0.4344422700587084\n",
      "Dev accuracy: 0.4522760646108664\n"
     ]
    }
   ],
   "source": [
    "result_train =  np.array([p_train2[i].argmax() for i in range(p_train2.shape[0])])\n",
    "result_test = np.array([p_test2[i].argmax() for i in range(p_test2.shape[0])])\n",
    "result_dev = np.array([p_dev2[i].argmax() for i in range(p_dev2.shape[0])])\n",
    "\n",
    "train_result = np.equal(train, result_train)\n",
    "test_result = np.equal(test, result_test)\n",
    "dev_result = np.equal(dev, result_dev)\n",
    "\n",
    "print(\"Train accuracy: \" + str(np.average(train_result)))\n",
    "print(\"Test accuracy: \" + str(np.average(test_result)))\n",
    "print(\"Dev accuracy: \" + str(np.average(dev_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Model 3 - 2nd Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.48238747553816047\n",
      "Test accuracy: 0.4691780821917808\n",
      "Dev accuracy: 0.4845814977973568\n"
     ]
    }
   ],
   "source": [
    "result_train =  np.array([p_train3[i].argmax() for i in range(p_train3.shape[0])])\n",
    "result_test = np.array([p_test3[i].argmax() for i in range(p_test3.shape[0])])\n",
    "result_dev = np.array([p_dev3[i].argmax() for i in range(p_dev3.shape[0])])\n",
    "\n",
    "train_result = np.equal(train, result_train)\n",
    "test_result = np.equal(test, result_test)\n",
    "dev_result = np.equal(dev, result_dev)\n",
    "\n",
    "print(\"Train accuracy: \" + str(np.average(train_result)))\n",
    "print(\"Test accuracy: \" + str(np.average(test_result)))\n",
    "print(\"Dev accuracy: \" + str(np.average(dev_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Model 4 - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.38454011741682975\n",
      "Test accuracy: 0.3703522504892368\n",
      "Dev accuracy: 0.3607440039158101\n"
     ]
    }
   ],
   "source": [
    "result_train =  np.array([p_train4[i].argmax() for i in range(p_train4.shape[0])])\n",
    "result_test = np.array([p_test4[i].argmax() for i in range(p_test4.shape[0])])\n",
    "result_dev = np.array([p_dev4[i].argmax() for i in range(p_dev4.shape[0])])\n",
    "\n",
    "train_result = np.equal(train, result_train)\n",
    "test_result = np.equal(test, result_test)\n",
    "dev_result = np.equal(dev, result_dev)\n",
    "\n",
    "print(\"Train accuracy: \" + str(np.average(train_result)))\n",
    "print(\"Test accuracy: \" + str(np.average(test_result)))\n",
    "print(\"Dev accuracy: \" + str(np.average(dev_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Model 5 - L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.313600782778865\n",
      "Test accuracy: 0.32093933463796476\n",
      "Dev accuracy: 0.3176700930004895\n"
     ]
    }
   ],
   "source": [
    "result_train =  np.array([p_train5[i].argmax() for i in range(p_train5.shape[0])])\n",
    "result_test = np.array([p_test5[i].argmax() for i in range(p_test5.shape[0])])\n",
    "result_dev = np.array([p_dev5[i].argmax() for i in range(p_dev5.shape[0])])\n",
    "\n",
    "train_result = np.equal(train, result_train)\n",
    "test_result = np.equal(test, result_test)\n",
    "dev_result = np.equal(dev, result_dev)\n",
    "\n",
    "print(\"Train accuracy: \" + str(np.average(train_result)))\n",
    "print(\"Test accuracy: \" + str(np.average(test_result)))\n",
    "print(\"Dev accuracy: \" + str(np.average(dev_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6643835616438356\n",
      "Test accuracy: 0.6453033268101761\n",
      "Dev accuracy: 0.6441507586882036\n"
     ]
    }
   ],
   "source": [
    "train_voting = np.array([train1, train2, train3, train4, train5])\n",
    "test_voting = np.array([test1, test2, test3, test4, test5])\n",
    "dev_voting = np.array([dev1, dev2, dev3, dev4, dev5])\n",
    "\n",
    "final_train = voting_calc(train_voting)\n",
    "final_test = voting_calc(test_voting)\n",
    "final_dev = voting_calc(dev_voting)\n",
    "\n",
    "print(\"Train accuracy: \" + str(np.mean(np.equal(final_train, result_train))))\n",
    "print(\"Test accuracy: \" + str(np.mean(np.equal(final_test, result_test))))\n",
    "print(\"Dev accuracy: \" + str(np.mean(np.equal(final_dev, result_dev))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Conclusions\n",
    "<br>\n",
    "<div style=\"text-align: justify\">Working with this assignment has been quite a challenge, since the dataset didn´t give us a way to easily train our model. We have spent much time figuring out how we could improve the test results we were obtaining at the beginning because they were quite low (around 0.45). This is the reason why we decided to launch a big amount of models and analyse them using TensorFlow, we wanted to choose the best hyperparameters we could. </div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">The use of Tensorboard was really helpful for this purpose. We were able to see also how the weights and other elements of the network evolved over time and was quite interesting. We have kept record of all the logs and models in case they were needed to complete this work.</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">Regarding the low test accuracy we obtained in the models tried, we think this can be due to the fact that the dataset is small and there are 10 different labels. Also the dataset could had been randomized according to the description and this can be another cause of the poor results and the early overfitting.</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">With our approach we have tried to use the different methods we have studied in class, nevertheless there are more combinations we didn´t explore and that could have lead us to better results like decreasing progressively the learning rate, tuning more the initialization parameters of the weights and bias, trying CNN approach by training layers in order, using other approaches like Adanet to automatically train ensembles or retaining always the best model of each run.</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">We decided to optimize time and this is why we did not try the methods above mentioned, we wanted to focus in have an overview of how the different models behaved because we thought this would help us to find the best model (instead of tuning concrete hyperparameters or automatic methods), we also wanted to learn about the use of tensorboard.</div>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">Finally, we could see in this approach the power of the ensemble methods, particularly of the voting system method, with which we were able to come up with a relatively better model coming from average ones.</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
